<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>
	Posts on A stats website
	
	</title>
    <link>/post/</link>
    <description>Recent content 
	
	in Posts on A stats website
	</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
	
	
    <lastBuildDate>Wed, 27 May 2020 00:00:00 +0000</lastBuildDate>
	
    
        <atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tidymodels and XGBooost; a few learnings</title>
      <link>/2020/05/tidymodels-xgboost/</link>
      <pubDate>Wed, 27 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/05/tidymodels-xgboost/</guid>
	  <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This post will look at how to fit an XGBoost model using the &lt;code&gt;tidymodels&lt;/code&gt; framework rather than using the &lt;code&gt;XGBoost&lt;/code&gt; package directly.&lt;/p&gt;
&lt;p&gt;Tidymodels is a collection of packages that aims to standardise model creation by providing commands that can be applied across different R packages. For example, once the code is written to fit an XGBoost model a large amount of the same code could be used to fit a C5.0 algorithm.&lt;/p&gt;
&lt;p&gt;I will look at a dataset which I have analysed before so I know what to expect and I can compare the &lt;code&gt;tidymodels&lt;/code&gt; steps with the ones I implemented originally.&lt;/p&gt;
&lt;p&gt;First let’s load the necessary packages. I’ll go through what each of the &lt;code&gt;tidymodels&lt;/code&gt; packages does as we go along. We also call &lt;code&gt;doParallel&lt;/code&gt; to enable parallelisation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;require(dplyr)
require(rsample)
require(recipes)
require(parsnip)
require(tune)
require(dials)
require(workflows)
require(yardstick)
require(knitr)
require(kableExtra)
require(xgboost)
require(ggplot2)
require(data.table)

#Parallelisation
require(doParallel)
cores &amp;lt;- parallel::detectCores(logical = FALSE)
registerDoParallel(cores = cores)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first step is to load in the data and apply any relevant pre-processing steps. Here I won’t focus on exploring the data, I’m more interested in following the &lt;code&gt;tidymodels&lt;/code&gt; workflow. Also, I can’t talk about the details of this dataset too much for privacy reasons.&lt;/p&gt;
&lt;p&gt;This dataset is already split in training and testing.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(mwTrainSet)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 10000    28&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;preprocessing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Preprocessing&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;recipes&lt;/code&gt; package can be used to handle preprocessing. You need to build a recipe object that will contain a number of different steps to be followed. This recipe can then be applied to other data, e.g. testing data or new data from the same source.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;recipes&lt;/code&gt; contains a large number of &lt;code&gt;step&lt;/code&gt; functions that aim to account for any necessity you will need in your preprocessing.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;myRecipe&amp;lt;- recipes::recipe(outcome ~ ., data=mwTrainSet) %&amp;gt;% 
  recipes::step_mutate(os = as.factor(os)) %&amp;gt;%
  recipes::step_mutate(ob = as.factor(ob)) %&amp;gt;%
  step_rm(id) %&amp;gt;%
  step_mutate(w50s = ifelse(ds&amp;lt;=0.5,&amp;#39;TRUE&amp;#39;,&amp;#39;FALSE&amp;#39;)) %&amp;gt;%
  prep()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is not my recipe in full but you can see how the process works. &lt;code&gt;os&lt;/code&gt; and &lt;code&gt;ob&lt;/code&gt; are logical variables and I want to convert them to factors as required by XGBoost. I’m also removing the &lt;code&gt;id&lt;/code&gt; variable and creating a new variable &lt;code&gt;w50s&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Here I would like to note that if the logical variables were categorical instead I could have used a step like &lt;code&gt;step_string2factor(all_nominal())&lt;/code&gt; to convert them all into factors at the same time. However, at this time I’m not aware that the required &lt;code&gt;all_logical&lt;/code&gt; or &lt;code&gt;step_logic2factor&lt;/code&gt; exist so I mutate the variables one by one. There is an open issue with this request &lt;a href=&#34;https://github.com/tidymodels/recipes/issues/193&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can find a list of all step functions available &lt;a href=&#34;https://recipes.tidymodels.org/reference/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now that the recipe is built we can use the &lt;code&gt;bake&lt;/code&gt; function to actually run our data through it. I will save the modified dataset in a new object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;proc_mwTrainSet &amp;lt;- myRecipe %&amp;gt;% bake(mwTrainSet)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;cross-validation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Cross-validation&lt;/h3&gt;
&lt;p&gt;Moving along the model-building pipeline we want to create some cross-validation folds from our training set. We will use these folds during the tuning process. For this purpose I use the &lt;code&gt;vfold_cv&lt;/code&gt; function from &lt;code&gt;rsample&lt;/code&gt; which in my case creates 5 folds of the processed data with each fold split with an 80/20 ratio. I also set the seed for reproducibility.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2020)
cvFolds &amp;lt;- mwTrainSet %&amp;gt;% 
  bake(myRecipe, new_data = .) %&amp;gt;%
  rsample::vfold_cv(v = 5)

cvFolds&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## #  5-fold cross-validation 
## # A tibble: 5 x 2
##   splits          id   
##   &amp;lt;named list&amp;gt;    &amp;lt;chr&amp;gt;
## 1 &amp;lt;split [8K/2K]&amp;gt; Fold1
## 2 &amp;lt;split [8K/2K]&amp;gt; Fold2
## 3 &amp;lt;split [8K/2K]&amp;gt; Fold3
## 4 &amp;lt;split [8K/2K]&amp;gt; Fold4
## 5 &amp;lt;split [8K/2K]&amp;gt; Fold5&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-specification&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model specification&lt;/h3&gt;
&lt;p&gt;We have a processed dataset and we know how we want to validate it so we can now specify the model we want to fit to the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xgmodel&amp;lt;-parsnip::boost_tree(
  mode = &amp;quot;classification&amp;quot;,
  trees = 1000, #nrounds
  learn_rate = tune(), #eta
  sample_size = tune(), #subsample
  mtry = tune(), #colsample_bytree
  min_n = tune(), #min_child_weight
  tree_depth = tune() #max_depth
) %&amp;gt;%
  set_engine(&amp;quot;xgboost&amp;quot;, objective = &amp;quot;multi:softprob&amp;quot;,
             lambda=0, alpha=1, num_class=3,verbose=1)

xgmodel&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Boosted Tree Model Specification (classification)
## 
## Main Arguments:
##   mtry = tune()
##   trees = 1000
##   min_n = tune()
##   tree_depth = tune()
##   learn_rate = tune()
##   sample_size = tune()
## 
## Engine-Specific Arguments:
##   objective = multi:softprob
##   lambda = 0
##   alpha = 1
##   num_class = 3
##   verbose = 1
## 
## Computational engine: xgboost&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;parsnip&lt;/code&gt; package provides an interface for many types of models and the different types of packages that fall into those types. For example, because XGBoost is a boosted tree type of model we use the &lt;code&gt;boost_tree&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;boost_tree&lt;/code&gt; provides general parameters that can be used on other boosted tree models. In my specification below I included the XGBoost translation of the &lt;code&gt;boost_tree&lt;/code&gt; names.&lt;/p&gt;
&lt;p&gt;Many of the parameters have a &lt;code&gt;tune()&lt;/code&gt; value assigned to them. This is because later we are going to construct a parameter grid with which we will be able to search what the best parameters are.&lt;/p&gt;
&lt;p&gt;Also note that &lt;code&gt;set_engine&lt;/code&gt; is where we set that we are using XGBoost and that we can pass XGBoost specific options into this function as well.&lt;/p&gt;
&lt;p&gt;By using &lt;code&gt;parsnip&lt;/code&gt; you avoid many of the pecularities that XGBoost has. If you used XGBoost directly you would find that you need to encode categorical variables as dummies, you also need to use the specific XGBoost format for matrices &lt;code&gt;xgb.DMatrix&lt;/code&gt; and you need to separate out the labels from the predictors.&lt;/p&gt;
&lt;p&gt;Here I didn’t need to do any of that because &lt;code&gt;parsnip&lt;/code&gt; handles those requirements internally. I think the &lt;code&gt;tidymodels&lt;/code&gt; framework makes your life easier but it’s wise to still know how the underlying engines work if you are going to use them.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tuning-the-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Tuning the model&lt;/h3&gt;
&lt;p&gt;We now turn to the &lt;code&gt;dials&lt;/code&gt; package. To me this is where &lt;code&gt;tiymodels&lt;/code&gt; provides its biggest benefits. It gives the user the ability to tune models in a reproducible manner that is easy to replicate.&lt;/p&gt;
&lt;p&gt;First, we need to set up a &lt;code&gt;parameters&lt;/code&gt; object with the parameters we want to be tuned.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xgboostParams &amp;lt;- dials::parameters(
  min_n(),
  tree_depth(),
  learn_rate(),
  finalize(mtry(),select(proc_mwTrainSet,-outcome)),
  sample_size = sample_prop(c(0.4, 0.9))
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that, &lt;code&gt;mtry&lt;/code&gt; had to be treated differently and we had to ‘finalize’ it. The reason being that for parameters whose range depends on the data set the user has to provide the range. As &lt;code&gt;mtry()&lt;/code&gt; is the number of variables used in the making of each tree we need to bound it by the number of variables available.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtry()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # Randomly Selected Predictors  (quantitative)
## Range: [1, ?]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;finalize(mtry(),select(proc_mwTrainSet,-outcome))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # Randomly Selected Predictors  (quantitative)
## Range: [1, 49]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another quirk we encounter here is that &lt;code&gt;boost_tree&lt;/code&gt; takes the parameter &lt;code&gt;sample_size&lt;/code&gt; as integer but XGBoost requires this parameter as a proportion, hence we use &lt;code&gt;sample_prop&lt;/code&gt; to specify the range.&lt;/p&gt;
&lt;p&gt;Once the parameters to be tuned are defined we can use the &lt;code&gt;grid_max_entropy&lt;/code&gt; function to create the grid that will be explored. The max entropy grid is defined like so in the documentation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Experimental designs for computer experiments are used to construct parameter grids that try to cover the parameter space such that any portion of the space has an observed combination that is not too far from it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, we are letting &lt;code&gt;dials&lt;/code&gt; define a grid for us that will explore as much as the parameter space as possible. I will set the number of combinations to 100.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2020)
xgGrid &amp;lt;- dials::grid_max_entropy(xgboostParams, size = 100)

#knitr::kable(head(xgGrid))
kablify(xgGrid[1:5,])&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
min_n
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
tree_depth
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
learn_rate
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
mtry
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
sample_size
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0017557
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.4202777
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000007
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.8233843
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000141
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.6387196
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000006
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.8828089
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0001357
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
41
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7991674
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This is great. When I first fit this model I was using a custom built function for tuning that I found on stackoverflow.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)
searchGridSubCol &amp;lt;- expand.grid(min_child_weight=c(2),
                                subsample = c(0.75,0.6,0.9), 
                                colsample_bytree = c(0.6,0.8),
                                lam = c(2),
                                alph=c(0),
                                depth=c(6,10,3),
                                etaa=c(0.009,0.011,0.013,0.014)
                                )
ntrees &amp;lt;- 5000
mllHyperparameters &amp;lt;- apply(searchGridSubCol, 1, function(parameterList){
  
  #Extract Parameters to test
  currentSubsampleRate &amp;lt;- parameterList[[&amp;quot;subsample&amp;quot;]]
  currentColsampleRate &amp;lt;- parameterList[[&amp;quot;colsample_bytree&amp;quot;]]
  currentMCW &amp;lt;- parameterList[[&amp;quot;min_child_weight&amp;quot;]]
  currentLambda &amp;lt;- parameterList[[&amp;quot;lam&amp;quot;]]
  currentAlpha &amp;lt;- parameterList[[&amp;quot;alph&amp;quot;]]
  currentDepth &amp;lt;- parameterList[[&amp;quot;depth&amp;quot;]]
  currentEta &amp;lt;- parameterList[[&amp;quot;etaa&amp;quot;]]
  
  xgb_params &amp;lt;- list(&amp;quot;objective&amp;quot; = &amp;quot;multi:softprob&amp;quot;,
                     &amp;quot;eval_metric&amp;quot; = &amp;quot;mlogloss&amp;quot;,
                     &amp;quot;num_class&amp;quot; = 3,
                     &amp;quot;eta&amp;quot; = currentEta,
                     subsample = currentSubsampleRate,
                     colsample_bytree= currentColsampleRate,
                     min_child_weight=currentMCW,
                     lambda=currentLambda,
                     alpha=currentAlpha,
                     max_depth=currentDepth)
})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I did quite an extensive search but I always chose values in incremental steps, e.g., for &lt;code&gt;eta&lt;/code&gt; I would try 0.1,0.15,0.2,… Using &lt;code&gt;dials&lt;/code&gt; you might get to combinations that you didn’t think about but mostly it’ll optimise how to set the parameter combinations given the size parameter.&lt;/p&gt;
&lt;p&gt;Next, we create a workflow from &lt;code&gt;workflows&lt;/code&gt; that we will pass into the tuning object in the following step. We specify the formula for the model we want to fit based on the dependent variable &lt;code&gt;outcome&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xgWorkflow &amp;lt;- 
  workflows::workflow() %&amp;gt;%
  add_model(xgmodel) %&amp;gt;% 
  add_formula(outcome ~ .)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can finally tune the model! We pass the workflow, cross-validation folds, grid of parameters to test and the metric we want to save from each model output. Note that &lt;code&gt;metric_set&lt;/code&gt; comes from the &lt;code&gt;yardstick&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xgTuned &amp;lt;- tune_grid(
  object = xgWorkflow,
  resamples = cvFolds,
  grid      = xgGrid,
  metrics   = metric_set(mn_log_loss),
  control   = control_grid(verbose = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tuning the model on that grid took a while, around 90 minutes in a 8-core machine runing in parallel.&lt;/p&gt;
&lt;p&gt;Since we are running parallelised code there is no progress output shown even though verbose is set to True.&lt;/p&gt;
&lt;p&gt;Also, note that I set the &lt;code&gt;trees&lt;/code&gt; parameter to 1000 in the model specification. This means that we are fitting 100 different XGBoost model and each one of those will build 1000 trees. XGBoost supports early stopping, i.e., you can specify a parameter that tells the model to stop if there has been no log-loss improvement in the last &lt;code&gt;N&lt;/code&gt; trees.&lt;/p&gt;
&lt;p&gt;Setting an early stopping criterion can save computation time. If there’s a parameter combination that is not performing well the model will stop well before reaching the 1000th tree.&lt;/p&gt;
&lt;p&gt;Early stopping is currently not supported in the &lt;code&gt;boost_tree&lt;/code&gt; function. However, according to this &lt;a href=&#34;https://github.com/topepo/caret/issues/641&#34;&gt;post&lt;/a&gt; it has been very recently implemented in the development version so you could give it a try if you were so inclined.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;xgTuned&lt;/code&gt; object contains the 100 combinations of parameters we tested and the corresponding mean log-loss from the cross-validation.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;show_best&lt;/code&gt; function outputs the best performing combinations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xgTuned %&amp;gt;% tune::show_best(metric = &amp;quot;mn_log_loss&amp;quot;) %&amp;gt;% kablify()&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
mtry
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
min_n
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
tree_depth
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
learn_rate
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
sample_size
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
.metric
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
.estimator
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
mean
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
n
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
std_err
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0086232
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.8386232
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
mn_log_loss
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
multiclass
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3126151
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0056380
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0153090
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7279057
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
mn_log_loss
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
multiclass
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3130304
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0073298
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
42
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0148805
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7756686
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
mn_log_loss
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
multiclass
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3147089
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0067372
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0147389
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.5218267
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
mn_log_loss
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
multiclass
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3196296
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0051067
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0178508
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.4542553
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
mn_log_loss
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
multiclass
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3210408
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0061055
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We can also get all the combinations with &lt;code&gt;collect_metrics&lt;/code&gt; and we can plot them against mean log-loss.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xgTuned %&amp;gt;% collect_metrics() %&amp;gt;% 
  select(mean,mtry:sample_size) %&amp;gt;% data.table %&amp;gt;% 
  melt(id=&amp;quot;mean&amp;quot;) %&amp;gt;% 
  ggplot(aes(y=mean,x=value,colour=variable)) + 
  geom_point(show.legend = FALSE) + 
  facet_wrap(variable~. , scales=&amp;quot;free&amp;quot;) + theme_bw() +
  labs(y=&amp;quot;Mean log-loss&amp;quot;, x = &amp;quot;Parameter&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-24-tidymodels-and-xgbooost-a-few-learnings_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;No clear patterns emerge from looking at the plots except that very small learn rate values lead to high log-loss. Having a grid that covers the parameter space as extensively as possible leads to many combinations that aren’t so great but the important point is that we get also get the ones that perform very well.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-the-best-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fitting the best model&lt;/h3&gt;
&lt;p&gt;We can pick the best combination of parameters with &lt;code&gt;select_best&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xgBestParams &amp;lt;- xgTuned %&amp;gt;% select_best(&amp;quot;mn_log_loss&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The model is then finalised with those parameters with &lt;code&gt;finalize_model&lt;/code&gt; and then the training data can be fit to it using &lt;code&gt;fit&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xgboost_model_final &amp;lt;- xgmodel %&amp;gt;% finalize_model(xgBestParams)
xgTrainFit&amp;lt;-xgboost_model_final %&amp;gt;% fit(outcome~., data=proc_mwTrainSet)
xgTrainFit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## parsnip model object
## 
## Fit time:  1m 2.2s 
## ##### xgb.Booster
## raw: 7.5 Mb 
## call:
##   xgboost::xgb.train(params = list(eta = 0.00862323672548215, max_depth = 6L, 
##     gamma = 0, colsample_bytree = 0.358490566037736, min_child_weight = 8L, 
##     subsample = 0.838623173511587), data = x, nrounds = 1000, 
##     verbose = 1, objective = &amp;quot;multi:softprob&amp;quot;, num_class = 3L, 
##     lambda = 0, alpha = 1, nthread = 1)
## params (as set within xgb.train):
##   eta = &amp;quot;0.00862323672548215&amp;quot;, max_depth = &amp;quot;6&amp;quot;, gamma = &amp;quot;0&amp;quot;, colsample_bytree = &amp;quot;0.358490566037736&amp;quot;, min_child_weight = &amp;quot;8&amp;quot;, subsample = &amp;quot;0.838623173511587&amp;quot;, objective = &amp;quot;multi:softprob&amp;quot;, num_class = &amp;quot;3&amp;quot;, lambda = &amp;quot;0&amp;quot;, alpha = &amp;quot;1&amp;quot;, nthread = &amp;quot;1&amp;quot;, silent = &amp;quot;1&amp;quot;
## xgb.attributes:
##   niter
## callbacks:
##   cb.print.evaluation(period = print_every_n)
## # of features: 53 
## niter: 1000
## nfeatures : 53&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also get predictions on the training set; &lt;code&gt;predict&lt;/code&gt; outputs the predicted classes while &lt;code&gt;predict_classprob.model_fit&lt;/code&gt; outputs the class probabilities for each of the 3 classes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xgTrainPreds&amp;lt;- xgTrainFit %&amp;gt;% predict(new_data=proc_mwTrainSet)
xgTrainPredProbs &amp;lt;- xgTrainFit %&amp;gt;% predict_classprob.model_fit(new_data=proc_mwTrainSet)
proc_mwTrainSet &amp;lt;- bind_cols(proc_mwTrainSet,xgTrainPreds,xgTrainPredProbs)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the table below &lt;code&gt;outcome&lt;/code&gt; is the dependent variable, &lt;code&gt;.pred_class&lt;/code&gt; the predicted class and &lt;code&gt;Type*&lt;/code&gt; are the class probabilities. As an example, in the first row Type2 has the highest probability so the prediction is assingnd to this class.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;proc_mwTrainSet %&amp;gt;% select(Type1:outcome) %&amp;gt;% head %&amp;gt;% kablify()&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Type1
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Type2
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Type3
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
.pred_class
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
outcome
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0591691
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9169078
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0239230
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Type2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Type2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.4554967
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.5316201
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0128832
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Type2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Type1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9568088
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0382318
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0049593
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Type1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Type1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0451100
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9463689
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0085212
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Type2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Type2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0335070
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0201417
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9463512
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Type3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Type3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0105972
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9814348
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0079681
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Type2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Type2
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;model-evaluation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model evaluation&lt;/h3&gt;
&lt;p&gt;We can evaluate the model using the &lt;code&gt;yardstick&lt;/code&gt; package. The &lt;code&gt;metrics&lt;/code&gt; function takes parameters &lt;code&gt;truth&lt;/code&gt; and &lt;code&gt;estimate&lt;/code&gt; and will output the accuracy and kappa metrics. If you pass the class probabilities it also calculates mean log-loss and roc_auc.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;proc_mwTrainSet %&amp;gt;% yardstick::metrics(truth=outcome,estimate=.pred_class,Type1,Type2,Type3) %&amp;gt;% kablify()&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
.metric
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
.estimator
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
.estimate
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
accuracy
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
multiclass
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9432000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
kap
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
multiclass
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9116029
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
mn_log_loss
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
multiclass
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1906783
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
roc_auc
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
hand_till
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9914153
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;When I first fit this model with XGBoost I got an accuracy of 0.96 and a validation log-loss of 0.306. So far with the current approach accuracy is at 0.943 and validation log-loss (from the &lt;code&gt;xgTuned&lt;/code&gt; table in the previous section) at 0.313. I haven’t achieved results as good as I had before but I also have to note that getting to those values took me a lot of effort and going through the tuning process many times. Here, I did one pass and I’m already close. If I expand the tuning grid I could probably get better performance metrics.&lt;/p&gt;
&lt;p&gt;We can also get the confusion matrix with &lt;code&gt;conf_mat&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cm&amp;lt;-proc_mwTrainSet %&amp;gt;% yardstick::conf_mat(truth=outcome,estimate=.pred_class) 
autoplot(cm, type = &amp;quot;heatmap&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-24-tidymodels-and-xgbooost-a-few-learnings_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can see that the &lt;code&gt;Type3&lt;/code&gt; class is better predicted than the other two.&lt;/p&gt;
&lt;p&gt;In order to &lt;em&gt;really&lt;/em&gt; finalise the model I would need to fit the test data and check the metrics in that set which has not been used in the modeling and hence provides an unbiased validation of out approach. I’m not going to focus on that here mainly because the test set did not come with labels so I won’t be able to calculate any performance metrics from it.&lt;/p&gt;
&lt;p&gt;If this was a real life case, once you were happy with the results in the test set you could put the model into production and make predictions on new data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Conclusions&lt;/h3&gt;
&lt;p&gt;This was a really quick tour around how &lt;code&gt;tidymodels&lt;/code&gt; works. I think it has many advantages and it definitively makes the task of fitting reproducible ML models faster and more user-friendly so it is certainly something I will keep playing with.&lt;/p&gt;
&lt;p&gt;I still think familiarity with the underlying models, in this case XGBoost, helps the user understand what this framework can and can’t do so I wouldn’t use it blindly without having some experience with the original model first.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Grand Slam title history as an animated bar chart race</title>
      <link>/2020/05/gs_gganim/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/05/gs_gganim/</guid>
	  <description>


&lt;p&gt;&lt;img src=&#34;/post/2020-05-15-grand-slam-title-history-as-an-animated-bar-chart-race_files/gganim6.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I’ve spoiled it by putting the gif at the start of the post but if you are interested in how it was made then read on!&lt;/p&gt;
&lt;p&gt;I’ve seen this kind of charts around the web so I wanted to make a tennis-related one and what better than using Grand Slam wins since the very beginning; 1877.&lt;/p&gt;
&lt;p&gt;The main package that is needed for the animation is gganimate. As the name suggests it integrates with ggplot to make an animation given many different charts and a transition variable.&lt;/p&gt;
&lt;p&gt;Let’s load the necessary packages&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;require(XML)
require(data.table)
library(httr)
require(dplyr)
require(stringr)
require(ggplot2)
require(gganimate)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we need to get the data for the chart.
Wikipedia helpfully has an article with all Grand Slam winner in history so we can pull the table within the article using &lt;code&gt;GET&lt;/code&gt; and &lt;code&gt;readHTMLTable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Once we know where the table is located in the HTML we can pull it into a data table.&lt;/p&gt;
&lt;p&gt;There are some kinks in the table we have to get rid off. For example, in 1977 there were two Austrlian Opens so the entry for 1977 is split into two rows but just one year.&lt;/p&gt;
&lt;p&gt;We then get rid of anything that is not a player name including special characters. Tjem the table is melted so we get one entry per year and Grand Slam.&lt;/p&gt;
&lt;p&gt;We also get rid of other stuff such as all the French Opens before 1925 because the tournament was not actually “open” and also instances when the tournaments were not held such as world wars.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gs&amp;lt;-data.table(tabs[[3]])

names(gs) &amp;lt;- as.character(unlist(gs[1,]))
gs&amp;lt;-gs[-1]

gs&amp;lt;-bind_rows(gs,data.table(Year=&amp;quot;1977&amp;quot;,&amp;quot;Australian Open&amp;quot;=&amp;quot;Vitas Gerulaitis&amp;quot;))

gs&amp;lt;-gs[grep(&amp;quot;[0-9]&amp;quot;,Year)][order(Year)]

gs &amp;lt;- melt(gs, id.vars = &amp;quot;Year&amp;quot;)

gs$winner &amp;lt;- gsub(&amp;quot;\\(([^)]+)\\)&amp;quot;,&amp;quot;&amp;quot;,gs$value)

gs$winner&amp;lt;-gsub(&amp;quot;[*]&amp;quot;,&amp;quot;&amp;quot;,gs$winner)
gs$winner&amp;lt;-gsub(&amp;quot;[†]&amp;quot;,&amp;quot;&amp;quot;,gs$winner)

gs$winner&amp;lt;-gsub(&amp;quot;Amateur Era ends&amp;quot;,&amp;quot;&amp;quot;,gs$winner)
gs$winner&amp;lt;-gsub(&amp;quot;Open Era begins&amp;quot;,&amp;quot;&amp;quot;,gs$winner)

gs[,winner:=str_trim(winner)]

gs[,.N,winner][order(-N)]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                      winner  N
##   1: tournament not created 43
##   2:                   &amp;lt;NA&amp;gt; 24
##   3:          Roger Federer 20
##   4:           Rafael Nadal 19
##   5:         Novak Djokovic 17
##  ---                          
## 167:           Rafael Osuna  1
## 168:         Manuel Orantes  1
## 169:           Andy Roddick  1
## 170:  Juan Martín del Potro  1
## 171:            Marin Cilic  1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gs&amp;lt;-gs[!(variable==&amp;quot;French Open&amp;quot; &amp;amp; Year&amp;lt;1925)]

gs[,win:=1]

gs&amp;lt;-gs[!grep(&amp;quot;tournament|started|WorldW|occupation|Tournament|oronavir&amp;quot;,winner)]

gs&amp;lt;-gs[winner!=&amp;quot;&amp;quot;]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now need to keep a running tally of anyone who has won at least one Grand Slam for every year so that they show up in our chart with the correct number of GS’s. This is what the &lt;code&gt;fun&lt;/code&gt; function is doing below.&lt;/p&gt;
&lt;p&gt;Additionally we also need to rank the players from most GS’s to least GS’s to create a rank variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Get a list of all the years
yearList&amp;lt;-gs[order(Year)][,unique(Year)]
#Function fun calculates cumulative GS wins for all the players up to the current year
fun&amp;lt;-function(year){ gs[Year&amp;lt;=year,.(win=sum(win),latestWin=max(Year)),.(winner)][,year:=year] }
#Create a table that has all combinations of year/player
gsfull&amp;lt;-lapply(yearList, fun) %&amp;gt;% rbindlist()

gsfull&amp;lt;-gsfull[order(year,-win,-latestWin)]
gsfull[,rank:=seq(1,.N),year]

gsfull[,win_label := paste0(&amp;quot; &amp;quot;, win)]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now start plotting our data. First create a tile plot with ggplot. Tiles work better than plot for this case because they slide into position in a nicer way when the plot transitions between years.&lt;/p&gt;
&lt;p&gt;A lot of the code I’m using I found over here in &lt;a href=&#34;https://stackoverflow.com/questions/53162821/animated-sorted-bar-chart-with-bars-overtaking-each-other&#34;&gt;stack overflow&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y&amp;lt;-1877

sp&amp;lt;-ggplot(gsfull[year&amp;gt;=y &amp;amp; rank&amp;lt;=30],aes(x=rank,y=win,fill=winner)) + 
  geom_tile(aes(y=win/2,height=win, width=0.95),alpha=0.9) + theme_bw() +
  geom_text(aes(y=0,label = paste0(winner,&amp;quot; &amp;quot;)), hjust = 1) +
  geom_text(aes(y=win,label = win_label, hjust=0)) +
  coord_flip(clip = &amp;quot;off&amp;quot;, expand = F) +
  scale_x_reverse() +
  guides(color = FALSE, fill = FALSE) +
  theme(axis.line=element_blank(),
        axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks=element_blank(),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        legend.position=&amp;quot;bottom&amp;quot;,
        panel.background=element_blank(),
        panel.border=element_blank(),
        panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(),
        panel.grid.major.x = element_line( size=.1, color=&amp;quot;grey&amp;quot; ),
        panel.grid.minor.x = element_line( size=.1, color=&amp;quot;grey&amp;quot; ),
        plot.margin = margin(5,5,5,5, &amp;quot;cm&amp;quot;)
        )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the base plot made it’s time to actually animate it. This is where &lt;code&gt;gganimate&lt;/code&gt; comes into play. The main funtion needed is &lt;code&gt;transition_states&lt;/code&gt; which takes a transition parameter, &lt;code&gt;year&lt;/code&gt; in our case, and animates the plot based on it.&lt;/p&gt;
&lt;p&gt;There’s a few extra bits in there; &lt;code&gt;enter_drift&lt;/code&gt; and &lt;code&gt;exit_shrink&lt;/code&gt; govern how the bars enter and leave the plot and &lt;code&gt;ease_aes&lt;/code&gt; controls how the bars switch around. There are many other options that &lt;code&gt;gganimate&lt;/code&gt; provides so this is just scratching the surface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- sp + transition_states(year, transition_length = 4, state_length = 2) +
  view_follow(fixed_x = TRUE)  +
  labs(title = &amp;#39;Grand Slam Titles : {closest_state}&amp;#39;)  +
   enter_drift(y_mod=10) + exit_shrink()  + 
  ease_aes(&amp;#39;linear&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally once the transitions are defined &lt;code&gt;animate&lt;/code&gt; takes the object and turns it into a gif or a video if you want depending on the renderer that you choose. The code below is what renders the plot at the start of this post.&lt;/p&gt;
&lt;p&gt;Duration and size parameters are passed by the user. Here I would like to note that if you call the plot &lt;code&gt;p&lt;/code&gt; it does get rendered but it looks different than the output you get with animate so I’d recommend always running &lt;code&gt;animate&lt;/code&gt; to see what the actual final output will be.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;animate(p, 1200, fps = 10,  width = 800, height = 600, 
        renderer = gifski_renderer(&amp;quot;gs_chart.gif&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And that’s it! As with most projects the trickiest part was getting the data in the format I needed it and then spent some time with aesthetic choices. The point being that once you have your data ready &lt;code&gt;ggplot&lt;/code&gt; and &lt;code&gt;gganimate&lt;/code&gt; provide an intuitive framework to create cool looking charts.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Analysing  tweets from the Virtual Madrid Open</title>
      <link>/2020/05/virtual-madrid-open/</link>
      <pubDate>Mon, 04 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/05/virtual-madrid-open/</guid>
	  <description>
&lt;script src=&#34;/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/jquery/jquery.min.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/leaflet/leaflet.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/leaflet/leaflet.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/leafletfix/leafletfix.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/Proj4Leaflet/proj4-compressed.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/Proj4Leaflet/proj4leaflet.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/rstudio_leaflet/rstudio_leaflet.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/leaflet-binding/leaflet.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;With the world in lockdown and no live tennis in the horizon in the near future the Madrid Open decided to organise an online tournament with male and female players facing each other using the Tennis World Tour video game.&lt;/p&gt;
&lt;p&gt;I was curious to see how fans reacted to the event. I downloaded twitter data using the rtweet package. I tried to include as many relevant terms as possible, the command I used was: &lt;code&gt;search_tweets2(q=&#34;#MMOPEN OR #PlayAtHome OR MutuaMadridOpen OR @MutuaMadridOpen&#34;,include_rts = F,n=18000)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The query retrieved ~7500 tweets from the last 9 days, executed on May 1st, which is enough to cover the duration of the tournament. I saved the data in a file to use later.&lt;/p&gt;
&lt;p&gt;Armed with the data we are ready to make some visualisations and text analysis. The tweet data is loaded in as a data.table with name &lt;code&gt;tw&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;tweet-map&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Tweet map&lt;/h3&gt;
&lt;p&gt;The tweets come with latitude and longitude coordinates for users who allowed their location to be known.&lt;/p&gt;
&lt;p&gt;Using leaflet we can plot the location of the tweets to get an idea of where they are coming from. Unfortunately only a very small proportion of tweets come with location information but we will map those anyway. There are other variables in the dataset that provide information about where the tweet comes from such as city, place but it’s not standardised in any way. These data could be used to derive coordinates if you were stubborn enough.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m &amp;lt;- leaflet() %&amp;gt;%
     addTiles() %&amp;gt;%  # Add default OpenStreetMap map tiles
    #addProviderTiles(&amp;#39;Stamen.Toner&amp;#39;) %&amp;gt;% 
     addMarkers(lat=tw[!is.na(lat),lat], lng=tw[!is.na(lng),lng],
                     popup=tw[!is.na(lng),text]) 
m  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:672px;height:480px;&#34; class=&#34;leaflet html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;options&#34;:{&#34;crs&#34;:{&#34;crsClass&#34;:&#34;L.CRS.EPSG3857&#34;,&#34;code&#34;:null,&#34;proj4def&#34;:null,&#34;projectedBounds&#34;:null,&#34;options&#34;:{}}},&#34;calls&#34;:[{&#34;method&#34;:&#34;addTiles&#34;,&#34;args&#34;:[&#34;//{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&#34;,null,null,{&#34;minZoom&#34;:0,&#34;maxZoom&#34;:18,&#34;tileSize&#34;:256,&#34;subdomains&#34;:&#34;abc&#34;,&#34;errorTileUrl&#34;:&#34;&#34;,&#34;tms&#34;:false,&#34;noWrap&#34;:false,&#34;zoomOffset&#34;:0,&#34;zoomReverse&#34;:false,&#34;opacity&#34;:1,&#34;zIndex&#34;:1,&#34;detectRetina&#34;:false,&#34;attribution&#34;:&#34;&amp;copy; &lt;a href=\&#34;http://openstreetmap.org\&#34;&gt;OpenStreetMap&lt;\/a&gt; contributors, &lt;a href=\&#34;http://creativecommons.org/licenses/by-sa/2.0/\&#34;&gt;CC-BY-SA&lt;\/a&gt;&#34;}]},{&#34;method&#34;:&#34;addMarkers&#34;,&#34;args&#34;:[[-38.19988735475,55.8761973,51.457877,-6.19621135,40.1687225,38.009443,55.13332045,55.1598345,55.1598345,55.1598345,55.1598345,55.1598345,51.59925535,28.1030125,-37.97256651425,39.55871005,39.55871005,39.55871005,39.55871005,39.55871005,39.55871005,39.55871005,39.55871005,50.1035907,50.1035907,50.1035907,26.4561475,-28.45340525,41.39265665,43.629311,43.27787125,43.27787125,-6.9155569,-6.9155569,7.42907465,42.394453,42.394453,6.49311225,43.2436283,25.5694737,25.5694737,25.5694737,25.5694737,25.5694737,25.5694737,25.5694737,34.0207895,35.9824705,29.8384948,-22.9333,36.251936,45.4091172,44.9346135,7.8786602,7.8786602,7.8786602,41.6916363,37.7706565,40.4777947,-33.4254004,28.1030125,40.4313888,41.6916363,37.10851325,40.31990335,15.2011325,15.2011325,15.2011325,44.787123,55.5486656,51.61188465,51.61188465,51.61188465,-33.8065285,30.0615955,34.0207895,49.3419815,42.8302591,53.1548066,53.1548066,51.67910325,41.14601905,41.14601905,41.14601905,41.14601905,41.14601905,51.5138971,55.94230005,28.4983765,35.4019815,35.4019815,35.4019815,35.4019815,50.05957995,40.655138,40.655138,40.655138,40.655138,6.6897024,-27.95422175775,52.76132755,43.73582845,57.1605562,32.6535835,35.8577,23.62541855,6.59061115,43.555244,43.555244,43.555244,43.555244,41.8984164,43.36888,45.92856115,45.92291295,40.3476735,53.8019562,29.8384948,52.11398,24.0983807,24.0983807,41.39265665,43.8806945,33.51674685,40.3341475,51.4108755,19.32838305,40.3005504,-33.429485,19.3261458,45.5578305,28.6384895,45.4827445,43.629311,40.00134,30.3834,30.3834,30.3834,30.3834,40.4,51.50378615,22.2624275,49.985057,-23.682803,50.98304269,45.0728727,35.2352865,-22.85186074,15.54795,55.466068,41.26028535,-37.97256651425,18.79171955,35.7539595,-29.85083595,53.5558197,52.01761005,50.984976,38.9293245,38.9293245,47.25082685,49.0869965,51.46468585,51.52483525,14.5464995,52.91553,53.6239735],[146.522074416,-3.1142899,-2.58539,106.8220717,-84.973784,-122.1178059,-6.66293985,-118.8117149,-118.8117149,-118.8117149,-118.8117149,-118.8117149,-0.018734,-15.45984895,145.053135344,3.249357,3.249357,3.249357,3.249357,3.249357,3.249357,3.249357,3.249357,-5.27126205,-5.27126205,-5.27126205,-80.0931798,21.26594485,2.14122735,-79.2725695,-1.9877106,-1.9877106,107.6174241,107.6174241,3.9052965,-71.2420715,-71.2420715,3.3386054,-2.2346623,85.1020385,85.1020385,85.1020385,85.1020385,85.1020385,85.1020385,85.1020385,-118.4119065,-83.9638415,-95.4464865,-43.2333,-78.9624499,12.1748172,-93.6626335,80.76465395,80.76465395,80.76465395,-0.92733235,-122.4359785,-3.70350755,-70.51891745,-15.45984895,-79.98068965,-0.92733235,-3.57099015,-3.89322605,-86.24319335,-86.24319335,-86.24319335,26.260548,-4.655906,-0.21089455,-0.21089455,-0.21089455,25.57926235,146.4647615,-118.4119065,-122.857891,-106.330781,-6.81533305,-6.81533305,-3.23023515,1.1243688,1.1243688,1.1243688,1.1243688,1.1243688,-3.42597775,-4.0086146,-81.386183,-80.6311314,-80.6311314,-80.6311314,-80.6311314,14.4658753,-73.9487755,-73.9487755,-73.9487755,-73.9487755,3.3352053,153.369361472,0.419867,11.1544972,-2.12704045,-96.55901125,-86.3947,-102.55803745,3.318066,-79.616073,-79.616073,-79.616073,-79.616073,12.54514535,-80.9843445,8.52277925,8.4322073,-74.0701315,-1.56549,-95.4464865,-2.0798,90.32870865,90.32870865,2.14122735,-79.2996725,-7.7794158,-74.2482833,-0.189289,-99.15234025,-3.6656669,-70.61075935,-99.6050475,-73.723025,77.095086,-75.6250379,-79.2725695,-74.1880345,-89.3727,-89.3727,-89.3727,-89.3727,-3.68333,-0.1891901,70.8960125,8.566941,-46.5955455,13.83831969,7.6757855,136.7583175,-43.29285691,121.09068,-4.62491655,-3.93390615,145.053135344,98.96891115,139.8539435,-51.1667104,-113.4926175,-0.22936815,-1.719032,-1.90194475,-1.90194475,9.581494,-122.2670745,-0.07060315,-0.1731149,121.03321235,-1.4707785,-113.121093],null,null,null,{&#34;interactive&#34;:true,&#34;draggable&#34;:false,&#34;keyboard&#34;:true,&#34;title&#34;:&#34;&#34;,&#34;alt&#34;:&#34;&#34;,&#34;zIndexOffset&#34;:0,&#34;opacity&#34;:1,&#34;riseOnHover&#34;:false,&#34;riseOffset&#34;:250},[&#34;Great comeback @Peter_Mitchell7 when goaded by Tim Watson tonight on @7NewsMelbourne on virtual Madrid Masters #MMOPEN \nTim with a smirk \&#34;\&#34;Well Mitch, if you want some real sport, there&#39;s a good game on @7mate tonight that you may enjoy.\&#34;\&#34; \nMitch \&#34;\&#34;It might be old but it&#39;s real!\&#34;\&#34;&#34;,&#34;@the_LTA @andy_murray @denis_shapo @MutuaMadridOpen Go Andy&#34;,&#34;@atptour @andy_murray @MutuaMadridOpen Well done ANDY !&#34;,&#34;#PlayatHome with STAR WARS figures and it comes with up 50% OFF\n.\nExclusive via Chat &amp;amp; Shop⁠\n.⁠\nGet CashBack 100K using BCA Credit Card (T&amp;amp;C apply)\n.\nFREE SHIPPING maximum IDR 20.000 for the first 50… https://t.co/6u77MhZAlE&#34;,&#34;@kikibertens @MutuaMadridOpen When you&#39;re good you&#39;re good play like you&#39;ve never played before okay&#34;,&#34;@PlayStation @AskPlayStation \nWill there be any more free games added to the #PlayAtHome initiative, maybe in May🤔?❓&#34;,&#34;@the_LTA @andy_murray @MutuaMadridOpen @NHSuk @atptour 💕💕💕💕💕💕💕&#34;,&#34;Most competitive match of the tournament so far 🎮 Well done on the battle @Bandreescu_ and pretty good result for your first tournament of the season 😊 Keep at ‘em! 🇨🇦 https://t.co/hXynTnvoSs&#34;,&#34;@TSN_Sports @TSNTennis Are you going to be broadcasting this, considering you have the rights to 900/1000 level events? 🤔 https://t.co/ffJg46yDM8&#34;,&#34;@TennisTheGame This @MutuaMadridOpen event really proves/highlights that game devs really need to up their level and release a comprehensive, high quality, @WTA @atptour player/sponsor sanctioned game with most top/popular players, on par with other top sports games 🤔&#34;,&#34;Note: Madrid is 6 hours ahead of the GTA, so if the time listed for @MutuaMadridOpen is local, than Bianca’s matches would start at 14:30 (2:30pm) Bianca time ⏰ https://t.co/cpIvQeW89h&#34;,&#34;For all the @Bandreescu_ fans out there, Bianca will play her first virtual matches on Monday the 27th starting NB 20:30 🇨🇦 I imagine the NB is “not before” but not sure what the time zone on that is; I’ll find out and add to this post 😊 https://t.co/wbVT77VRTm https://t.co/PzdJRi3CWn&#34;,&#34;You love to see it https://t.co/Dfkenk382m&#34;,&#34;@MutuaMadridOpen @andy_murray @TennisChannels Madre mía Goffin, pecho frío hasta en la play ... 😂😂😂&#34;,&#34;Walkover😂 https://t.co/Q0nkrsMkNN&#34;,&#34;Andy! https://t.co/ssjah9AIYl&#34;,&#34;He hecho unos cuantos sorteos de cuadros... ¡Pero hoy haremos uno muy especial! A las 16:00 os espero con @Rafael_Plaza para el sorteo en directo del @MutuaMadridOpen Virtual! ¡La lista de jugadores es 🔝! ¡No llegues tarde, @feliciano_lopez!\n\n🎥: https://t.co/ZUMaINsgXE https://t.co/ifk1sKiddC&#34;,&#34;¡Partidazo entre @DavidFerrer87 y @dieschwartzman para arrancar el @MutuaMadridOpen Virtual Pro!\n\n🎥: https://t.co/4zAhqNW1VU https://t.co/Pm4h9jzZm2&#34;,&#34;@miguelangeldaza @MutuaMadridOpen ¡Así lo haré! Son un equipo 🔝&#34;,&#34;Finalizó el @MutuaMadridOpen Virtual Pro con las victorias de Murray y Bertens. \n\nMe quedo, por encima de todo, con la solidaridad de muchísimas personas  que han donado y que han invertido su tiempo y cariño para hacerlo posible. 👏🏻👏🏻 https://t.co/hMhFOtPRtN&#34;,&#34;Hoy hemos celebrado con @atptour  y @WTA el sorteo del @MutuaMadridOpen Virtual Pro. ¡Os animo a seguirlo desde el lunes! Las causas benéficas merecen la pena. \nThanks @Rafael_Plaza! \n\n👉🏻 https://t.co/fkeYqdyoQR https://t.co/HCXLr1OWUs&#34;,&#34;@stewieALQ @DavidFerrer87 @dieschwartzman @MutuaMadridOpen Están en ello. Se solucionará. Quedémonos con lo positivo 😊&#34;,&#34;¡Arrancamos el sorteo del @MutuaMadridOpen Virtual PRO!\n\nhttps://t.co/ngMrOwcVtA&#34;,&#34;@MutuaMadridOpen @WTARomania I’ve got a reason to live again, it’s completion, the sea, it may be small but it’s a huge hope for you all. Romania forever Hallep foreve big waves for Nathan. Never give up. It’s soul.&#34;,&#34;@MutuaMadridOpen @dieschwartzman @andy_murray Come on Andy&#34;,&#34;@simonahalep5 @Simona_Halep @MutuaMadridOpen Babe!! Im going slightly grey in my hair (silver surfer). Before we get too old. I’m well today. Have a great day. Tony, Darren, nik, Arti dNiel and Tania and friends and family peace be with you&#34;,&#34;@TennisChannel @andy_murray @MutuaMadridOpen Three Grand Slams, 14 @ATPMasters titles, 2 Olympic Gold in singles and a Davis Cup win. Now @andy_murray can add the @MutuaMadridOpen Virtual Pro title to his collection. Sport&#39;s new reality! Well played Andy &amp;amp; well done to @feliciano_lopez &amp;amp; his staff for an innovative idea!&#34;,&#34;@atptour @MutuaMadridOpen @andy_murray The champion is back🎉🎉 @andy_murray&#34;,&#34;That tie break was genuinely tense! 😂 https://t.co/tdTsZeKab1&#34;,&#34;The #MMOpen tweeting results of Virtual Pro with headlines. How far we have fallen in the world of sport. Goodness. I know they desperately need content, but it&#39;s so incredibly cringeworthy 😂&#34;,&#34;Como termino el @David__Goffin v @StefTsitsipas the game in @MutuaMadridOpen ... #virtualtenis&#34;,&#34;@BelindaBencic ETXERA @nataliallovovic #virtualtenis @ConexionTDP_tve @feliciano_lopez  @kikibertens AURRERA..engancha el #virtualtenis .. @MutuaMadridOpen&#34;,&#34;#athome si Boi coba2 main air gerimis. Trus doi seneng, ga mau masuk😅.\n#kangenjalanjalan tapi #dirumahajadulu #keluarseperlunya\n.\n.\n.\n#stayathome against #covid_19 #playathome #2020 #april #denzelgabrieltheonardy… https://t.co/j5g8sxwG45&#34;,&#34;Lil designer &amp;amp; his tab. 😎\n#kangenjalanjalan tapi #dirumahajadulu #keluarseperlunya\n.\n.\n.\n#athome #stayathome against #covid_19 #playathome #2020 #may #denzelgabrieltheonardy #davidvaniajourney #familylife @ Salt &amp;amp;… https://t.co/n9SickzCuB&#34;,&#34;Toor okay https://t.co/dUJ5REQbkk&#34;,&#34;Yes https://t.co/OuWefQoW5O&#34;,&#34;Class act from @dieschwartzman https://t.co/jVV2mJdj4D&#34;,&#34;What game is this\nI think it&#39;s sacrilegious that we&#39;ve not had a top tier tennis game in close to a decade https://t.co/kqW751swuN&#34;,&#34;@BelindaBencic @MutuaMadridOpen 🔝performance&#34;,&#34;subscribe - https://t.co/lVejK0bmPA\n\n#gharbaithoindia #LifebuoyKarona #playathome #abhishekanand4u #foryou #foryoupage https://t.co/gClrP4EUW3&#34;,&#34;subscribe - https://t.co/lVejK0sXH8\n\n#gharbaithoindia #LifebuoyKarona #playathome #abhishekanand4u #foryou #foryoupage https://t.co/LfrewKFupx&#34;,&#34;subscribe - https://t.co/lVejK0bmPA\n\n#gharbaithoindia #LifebuoyKarona #playathome #abhishekanand4u #foryou #foryoupage https://t.co/goSCX03kkz&#34;,&#34;subscribe - https://t.co/lVejK0bmPA\n\n#gharbaithoindia #LifebuoyKarona #playathome #abhishekanand4u #foryou #foryoupage https://t.co/M6DFPSdbdQ&#34;,&#34;subscribe - https://t.co/lVejK0bmPA\n\n#gharbaithoindia #LifebuoyKarona #playathome #abhishekanand4u #foryou #foryoupage https://t.co/HyO9A2yo1D&#34;,&#34;subscribe - https://t.co/lVejK0bmPA\n\n#gharbaithoindia #LifebuoyKarona #playathome #abhishekanand4u #foryou #foryoupage https://t.co/nclDCvzIkK&#34;,&#34;subscribe - https://t.co/lVejK0bmPA\n\n#gharbaithoindia #LifebuoyKarona #playathome #abhishekanand4u #foryou #foryoupage https://t.co/YTgdhFa7a0&#34;,&#34;Ouuuu #escaperoom #PlayAtHome https://t.co/9l6M0Kdd4V #affiliate https://t.co/DHnyj4vSyt&#34;,&#34;Tomorrow night I have to choose between #playathome d&amp;amp;d, the @parksandrecnbc reunion, or the Three 6/Bone Thugz Instagram #Verzuz. Truly a king’s ransom of quarantine activities. My modem can handle all three, but can my heart?&#34;,&#34;#WTA La tenista Louisa Chirico jugando en el @MutuaMadridOpen en el 2016. El Mutua Open se hubiera celebrado esta semana. @Louisa_Chirico 🎾 https://t.co/4FkLTWv4KY&#34;,&#34;I recorded this video for the PRS guitars challenge!\n\n@prsguitars \n#Playathome\n#myPRS em Tijuca, Rio De Janeiro, Brazil https://t.co/DWLyZYa0dd&#34;,&#34;You can help our #healthcareheroes &amp;amp; other essential employees during the #COVID19 pandemic. \n\nHow? #StayatHome &amp;amp; #PlayatHome in #Durham. https://t.co/lSByWqtZu9&#34;,&#34;@MutuaMadridOpen @dieschwartzman @andy_murray Is it a joke? The correct score is 3-0! https://t.co/feYNJjwtty&#34;,&#34;@BorjaIglesias9 @MutuaMadridOpen @brunonieto_ No más faltó que bailes 😂🤣 https://t.co/fijdHzOdAj&#34;,&#34;Watching #Techstorm #esports on @dialoglk TV @Quantic_Dream&#39;s #DetroitBecomeHuman one helluva video game. I am watching this &amp;amp; I&#39;m playing #BeyondTwoSouls these days which is a awesome game too, loving it. @EllenPage performance is epic. #Sony #PlayStation4 #PlayAtHome #StayHome https://t.co/CvfX5V9VIs&#34;,&#34;Just now finished #BeyondTwoSouls absolutely brilliant @Quantic_Dream #DavidCage. @EllenPage &amp;amp; #WillemDafore both of your acting is simply magnificent. I chose #Life #Sony #Playstation4 #StayHome #PlayAtHome https://t.co/QjVdHiCDWw&#34;,&#34;Video games and unemployment... Not losing my mind, not at all... Thank you #Sony #Playstation4 #StayHome #PlayAtHome #LKA #SRILANKA&#34;,&#34;@BorjaIglesias9 @MutuaMadridOpen @brunonieto_ Jajajjajajaa, que Showman estas hecho...&#34;,&#34;“We’ll Meet Again” piano cover Quarantine Cabaret w Kitten on the Keys https://t.co/0N4YpjcB5g via @YouTube @kittenonthekeys #piano #playathome #quarantinecabaret #wellmeetagain&#34;,&#34;¿Podemos decir que los juegos del @PSPlusES de este mes son 1 mierda?\nConfirmamos, los juegos de este mes son una auténtica mierda pinchada en 1 palo. \nEsperemos que saquen un 2@ #PlayAtHome mejor, porque no veas... se han lucido totalmente 😂😂😂😂 https://t.co/FDCm1t7wSy&#34;,&#34;@ATPTour_ES @andy_murray @feliciano_lopez @MutuaMadridOpen Andi yu si mi?&#34;,&#34;@Gravesen_1 @MutuaMadridOpen Te llevaste la victoria esta vez, aunque espero poder tener una revancha! 😉 Un placer y mucha suerte en la siguiente ronda 💪🏻&#34;,&#34;All you need to make music is  ❤💜💙💚💛\nEnjoy this piece \&#34;\&#34;Quaratine\&#34;\&#34; by Camilo Jauregui performed by Mr. DeLuca from his kitchen counter! 🍴🥣🧂🥛🎶\n#PlayAtHome\n#MusicAnywhere #MusicEverywhere https://t.co/bke74aDg7P&#34;,&#34;@BorjaIglesias9 @MutuaMadridOpen @brunonieto_ Contra quién toca hoy???&#34;,&#34;@BorjaIglesias9 @MutuaMadridOpen @brunonieto_ 🤣 🤣 Muy top!&#34;,&#34;@BorjaIglesias9 @MutuaMadridOpen @brunonieto_ ÍDOLO 🤣🎾&#34;,&#34;@BelindaBencic @MutuaMadridOpen Go Belinda and get yourself into the second round of @MutuaMadridOpen!&#34;,&#34;@ESPNtenis @MutuaMadridOpen @ElinaSvitolina @AngeliqueKerber @KaPliskova @DonnaVekic All of them beautiful!&#34;,&#34;@atptour @fabiofogna @MutuaMadridOpen La idea de este torneo virtual es genial!&#34;,&#34;@MutuaMadridOpen @sorana_cirstea @ElinaSvitolina @JohannaKonta @vika7 Sorana 😍&#34;,&#34;The quarter-final line-up for the Mutua Madrid Virtual Pro has been set.\n\nToday’s match-ups include: \n\n🇬🇧Andy Murray vs 🇩🇪Alexander Zverev\n🇦🇷Diego Schwartzman vs 🇮🇹Fabio Fognini\n🇬🇷Stefanos Tsitsipas vs 🇪🇸David Ferrer\n🇧🇪David Goffin vs 🇫🇷Benoit Paire\n\nWho’s your pick? \n\n#MMOPEN&#34;,&#34;Wendy Darling as a pirate! 🏴‍☠️ YES! Can’t wait for me &amp;amp; Pops to try this one out. 👍🏴‍☠️ FREE play to download fellow parents /anyone with kids to entertain OR if you need some theatrical fun today 🥳 #PlayAtHome https://t.co/PsMIbGrSk8&#34;,&#34;Thrilled to be co-producing this with @RachelBarnett02 &amp;amp; our company @flyhighstories FREE NEW PLAYS for you to do AT HOME! For families or for anyone who loves #theatreforyoungaudiences stay safe stay at home #PlayAtHome https://t.co/1xieEryndT&#34;,&#34;ITS READY! @flyhighstories AT HOME project. First THREE plays are online ready for families to read/perform/play with at home for FREE. I’m so excited &amp;amp; proud of this. Please check them out! #playathome https://t.co/l2OGc7vPK9&#34;,&#34;Car number 2 done: Shout out to the best crew in the streets of @CSRRacing \n#PlayApartTogether \n#ilovecars \n#CSRRacing \n#PlayAtHome https://t.co/97CzfSB6Qc&#34;,&#34;こんな時だからこそ大量断捨離‼️\nたくさんのピアス、さようなら👋\n\nhttps://t.co/SUz3pwDVWc\n\n#大掃除 する #おうち時間 👍💡\n\n#stayhome #おうちエブリ #ピアス好きと繋がりたい #ピアス女子 #STAYHOME週間 #ステイホーム #StaySafe #断捨離 #PlayAtHome https://t.co/olPBJQbepv&#34;,&#34;Late Show with Stephen Colbert: John Fogerty \&#34;\&#34;Have You Ever Seen The Rain\&#34;\&#34; - #PlayAtHome https://t.co/TB7Wr2T3Og via @YouTube&#34;,&#34;Miss them games #basketball #hockey #sport #rugby @SportHostingVan @MyVancouver #Vancouver #PlayAtHome https://t.co/rpE78sqVWU&#34;,&#34;John Fogerty \&#34;\&#34;Have You Ever Seen The Rain\&#34;\&#34; - #PlayAtHome https://t.co/RMsenN9xgF via @YouTube&#34;,&#34;@BellshawGeorge @MutuaMadridOpen when did Svitolina and Konta play this and how come it wasn’t streamed? Thanks&#34;,&#34;@shawnspencer96 @MutuaMadridOpen @sorana_cirstea https://t.co/KHGbIxuDGg&#34;,&#34;@the_LTA @JohannaKonta @MutuaMadridOpen @CaroWozniacki How do I watch this virtual tennis?&#34;,&#34;@David___Llorens @adellfdez @MutuaMadridOpen @Doural28 No me hace falta animarme, estoy con ella en casa jugando un rato! https://t.co/t518rykC7x&#34;,&#34;@David___Llorens @charlyygarcia_ @MutuaMadridOpen @Doural28 @Adr11an_ @Monleon_P @DrefanHardy @Cristian10VM @TheMagician5GS @AlejanMilos @RealNiKLo https://t.co/Hpt2Va7r60&#34;,&#34;#TeamBibi #TeamVika https://t.co/8WG6s7QSNl&#34;,&#34;Elina dejándose perder para que no pase Vika, lamentable. Los celos porque Monfils quiere más a Vika que a ella https://t.co/9RdpD7WuM0&#34;,&#34;@MutuaMadridOpen @Bandreescu_ https://t.co/BhcDeOTW0A&#34;,&#34;We have created a video with some ideas of activities for you to do whilst at home head over to YouTube for the full video\nhttps://t.co/1Ke1Evh8yd\n\n#StayHome #PlayAtHome #COVID19 https://t.co/hz4iFhGc9T&#34;,&#34;@the_LTA @andy_murray @RafaelNadal @MutuaMadridOpen Prefer @andy_murray doing his own commentary 😁&#34;,&#34;@Madison_Keys @MutuaMadridOpen https://t.co/N1ohXry2za&#34;,&#34;@MutuaMadridOpen @nikkori89506411 Nishikori. ❤️🎾❤️🎾 Go Kei.&#34;,&#34;@MutuaMadridOpen Please do a tweet giving viewing methods. I&#39;m sure you have already, but now you need to make at least 2 or 3 tweets about this. Starting times only help if you know where to find it. Thank you from all of us who missed this info before. ❤️🎾❤️🎾❤️😎😎&#34;,&#34;@MutuaMadridOpen I couldn&#39;t follow your schedule. Didn&#39;t seem accurate. Will it be better? Also, every time I went to watch, all I saw were commentators and snippets of matches.&#34;,&#34;@keinishikori @MutuaMadridOpen Go Kei! 💪💪🎾❤️🎾❤️&#34;,&#34;První výhra @KaPliskova na @MutuaMadridOpen 😅 (3:1) https://t.co/RWS4vrHslJ&#34;,&#34;Stream dying when Isner plays, we stan @MutuaMadridOpen&#34;,&#34;Most winners in Caroline Wozniacki’s career https://t.co/1LJbn6iYvg&#34;,&#34;Kill her Donna 🥵 https://t.co/EBmMN2xkl9&#34;,&#34;The @MutuaMadridOpen is shaking https://t.co/QVE3OfPuib&#34;,&#34;Were you able to watch these games @LifeOfAdunni? https://t.co/4rVBA3gFIw&#34;,&#34;This is going to be epic! If you’re a #StarWars fan and love a bit of #trivia, be sure to get a team together, have a laugh and get involved. Comp starts May 4th at 6pm AEST on https://t.co/CV8XNXE1Fz #aussieED #PlayAtHome  #starwarstrivia #edutwitter https://t.co/NBvL1TtFZZ&#34;,&#34;@MutuaMadridOpen Nishikori&#34;,&#34;@BelindaBencic @MutuaMadridOpen https://t.co/PTR31Mvd7N&#34;,&#34;This is great! 🙌🏽 #buildingresiliance #PlayAtHome https://t.co/nMJglqe4lS&#34;,&#34;@AngeliqueKerber @MutuaMadridOpen Hello beautiful&#34;,&#34;When you send your video guy a take and he sends this back as your thumbnail pic for the song! To check out the next one, hit that YouTube link in bio and subscribe much appreciated\n.\n.\n.\n#myprs #playathome… https://t.co/Md6aLIRclQ&#34;,&#34;@KaPliskova @MutuaMadridOpen Omg i love that Dual! 😍😍😍&#34;,&#34;@LifeOfAdunni @JJlovesTennis @MutuaMadridOpen @JohannaKonta 😍😍&#34;,&#34;Genie 🇨🇦 will play 2 matches tomorrow in the virtual @MutuaMadridOpen \nFirst Match \nBouchard vs Vekic\n\nSecond Match\nBouchard vs Bertens\n\n#Geniearmy🎾 #Webelieveinbouchard @geniebouchard goodluck u got this 👍👍👍👍&#34;,&#34;Bianca 🇨🇦 will play 2 matches on the virtual @MutuaMadridOpen tournament\n\nFirst Match\nBianca vs Wozniacki\n\nSecond Match\nBianca vs Keys \n\n#bianca #andreescu @Bandreescu_ good luck on the tournament&#34;,&#34;Bibi 🇨🇦 wins 4-3 in a tiebreaker #virtualmadridmudala @MutuaMadridOpen&#34;,&#34;Lets go Eli good luck on the tournament @MutuaMadridOpen even thought it&#39;s virtual #FamEli #mutuaMadridopen @ElinaSvitolina https://t.co/v7GvlX6Tv2&#34;,&#34;vamos Peque carajo https://t.co/4PYsqqXcve&#34;,&#34;@KaPliskova @MutuaMadridOpen I bet you lost on purpose ☘️🎾&#34;,&#34;Il genio di @feliciano_lopez e tutti gli sono andati dietro 🤣🤣🤣🤣\nDa @Eurosport_ES alla @BBCSport passando dal @CorSport...\nUn genio 🤣🤣🤣🤣\n#MMOPEN #Nadal https://t.co/VzKmtLIRbU&#34;,&#34;Vamos a Ganar 💪🏼🎾🎮🤣🤣\n#VamosRafa #MMOPEN https://t.co/v8JDZagHD4&#34;,&#34;Connected Coaches Episode #2 with @FocusGolfGroup @RudyGonzalezIII and @Blazer_Justin. We talk about indoor putting drills and how to keep your game sharp at home. Episode #3 coming later this week! https://t.co/lUoNcwAwGY via @YouTube #ConnectedCoaches #GolfTips #PlayAtHome&#34;,&#34;This is so captivating! Watching top professional tennis players play each other on the play station! Loving it! Will you be doing a special podcast @TennisPodcast ? 😆 https://t.co/hLcbLQiJwM&#34;,&#34;Wildcat Tennis! Click on the blog to view Best Stretches for Tennis Players @Humble_Tennis #elevatetoexcellence  #wildcatPRIDE #PlayAtHome #TennisAtHome #HealthyAtHome #tennis @HumbleISD @HumbleISD_HHS @HumbleISD_Ath https://t.co/BAYdF1Bbl4&#34;,&#34;Evening S&amp;amp;C following my edgbastonpriorytennis home training programme. Today was lower body, will be also doing some footwork drills.  Had a bit of the @mutuamadridopen virtual tennis on in the background 🎾🎮… https://t.co/V0KS5pDMsM&#34;,&#34;@rnadalacademy @RafaelNadal @MutuaMadridOpen Vamos Rafa&#34;,&#34;Vamos Babe @RafaelNadal https://t.co/AirqbR7mtD&#34;,&#34;@MutuaMadridOpen virtual tournament is not a bad idea but can the commentators shut the fuck up and let hear @JohnIsner and Schwartzman?&#34;,&#34;@BelindaBencic @MutuaMadridOpen 😂👏🏼&#34;,&#34;@KaPliskova @MutuaMadridOpen 🤝&#34;,&#34;@MutuaMadridOpen @feliciano_lopez The English link doesn&#39;t work https://t.co/RRY5aigNsR&#34;,&#34;@MutuaMadridOpen @KaPliskova @fioferro Eek!&#34;,&#34;Jajajaja venga manacori #nadal #madridvirtual #mutuamadridopen\nHabría que ver las habilidades predeterminadas en la consola a uno y otro jugador. https://t.co/CcaWIWuG8e&#34;,&#34;@viciuslab @MutuaMadridOpen Dale primo dale!!!&#34;,&#34;@BelindaBencic @MutuaMadridOpen Visualization 😉&#34;,&#34;Lo de hoy... #pandemicbarbie #stayhome #quedateencasa #Barbie #barbiedoll #PlayAtHome https://t.co/nQEHUs3qrC&#34;,&#34;@jessicamimi7 @MutuaMadridOpen After what thiem said yesterday?&#34;,&#34;Participate in a contest of Game of Scores and stand a chance to win #REALCASH upto 1 Lakh!*\rRegister Now: https://t.co/Um8RM4BZqy\r\r#Gamming #WinRealCashPrize #PlayAtHome #gharpebaithochallenge #ContestAlert  #QuizTimeMorningsWithGameofScores  #MondayMotivaton #MondayMorning https://t.co/6ssJS9qys2&#34;,&#34;@MutuaMadridOpen @geniebouchard @DonnaVekic Go Genie🇨🇦&#34;,&#34;Thanks @PlayStation, what a great initiative! \n\nDon’t forget to grab your #free games here: https://t.co/aQeLUaWjKH\n\n#StayHome #PlayAtHome https://t.co/PggOBGp0uG&#34;,&#34;@ElinaSvitolina @MutuaMadridOpen @Nikecourt @Hublot Great shots!!!⭐️👌💪👊👍☝️🔥&#34;,&#34;@gish this one is for #teamspnbtchjrk duplicate a TV dinner challenge #gish #playathome #gishplayathome2020 #spnfamily #tvdinner @ Diamondhead, Mississippi https://t.co/NPUSNNWUqi&#34;,&#34;@gish this one is for #teamspnbtchjrk video call/ugly shirt challenge #gish #playathome #gishplayathome2020 #spnfamily #uglyshirt @ Diamondhead, Mississippi https://t.co/9x9s8PiQ4v&#34;,&#34;@gish this one is for #teamspnbtchjrk toilet paper altar challenge #gish #playathome #gishplayathome2020 #spnfamily #toiletpaper @ Diamondhead, Mississippi https://t.co/xGWVDmZ975&#34;,&#34;@gish this one is for #teamspnbtchjrk virtual hug challenge #gish #playathome #gishplayathome2020 #spnfamily #virtualhug done with my bff @jeanellesonnier @ Diamondhead, Mississippi https://t.co/SXNEjCQKKt&#34;,&#34;El peque ya tiene su primer rival del #mmopen 👦🏼👦🏼\n.\nTODA LA INFO en en https://t.co/O6v39Tvfxu\n.\n.\n.\n.\n.\n.\n.\n.\n#AtpTour #AtpWorldTour #Wta #TenisMasculino #TenisFemenino #TenisTime #TennisPlayers #TennisAtHome… https://t.co/uWF5Bl006V&#34;,&#34;Few to get you going... enjoy!\n\nHeating\nAl Pacino battles Robert Di Niro for control of the thermostat.\n\nGhosting \nAn autobiographical tale of a serial Tinder dater. \n\nReservoir Dogging \n- I’d rather not say... 😁\n\n#IsolationGames #PlayAtHome https://t.co/S0ipVZIa5B&#34;,&#34;INDIA WON WORLD CUP 🏏🇮🇳\n#WCC2 #PlayAtHome #CricketConnected #WorldCup #kingkohli #MSDhoni #enjoyathome https://t.co/A4wfDRgUiJ&#34;,&#34;@ElinaSvitolina @MutuaMadridOpen @Nikecourt @Hublot Sexy&#34;,&#34;E o torneio de tênis de Madrid que, ao ser cancelado pelo Corona, decidiu: “quer saber? Vamos manter esse treco pelo vídeo game mesmo!”. Sensacional.  😂 https://t.co/q9c2xQfZ6F&#34;,&#34;#playground #quarantine #nokids #silence #silencio #bobcat #play #playathome #toys #toystory #toystagram #playtime #kids #kidsroom #nature #outsideisfree #outsideisfree #mitkindernunterwegs #baby @ Großluga, Sachsen,… https://t.co/fjlIQgc1N4&#34;,&#34;The main actors of the WWII\n#warzag #strategic #boardgame #history #giochidatavolo #ComingSoon #followme #oninstagram #PlayAtHome #players #leaders #WorldWar2 #boardgames #italy #Germany #uk #Russia #basegame #comment #support #project https://t.co/WGoMaCejvu&#34;,&#34;@keinishikori @MutuaMadridOpen 圭くんおうえんしてるよ\nがんばって https://t.co/a5SCc9mAlM&#34;,&#34;Carpe diem \n🍃\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n#brasil🇧🇷 #carpediemplanner #instabeaches #ilhagrande_bra #ilhagrande #playathome #nacagi #saturdayvibes #sol #bikini #nacagiphoto #canonphotography… https://t.co/lxFkQbastA&#34;,&#34;20200425\nAbra Community Day 💙💛❤️\n\npokemongoapp\nnianticlabs\n\n#PokemonGo #abracommunityday #counter #fastmove #pokemon #PlayAtHome #StaySafe #StayHome #InvestigatingIllusions #psychic #FingerAbs @ Palayan City https://t.co/OC2w0e8nF9&#34;,&#34;@MutuaMadridOpen Had tickets to come to the real thing in Madrid. Will pour a long cool drink and watch this instead...from the sofa in Scotland.&#34;,&#34;@sacary7 @MutuaMadridOpen Pero si no das una bien.&#34;,&#34;@CarlaSuarezNava @MutuaMadridOpen @WTA Vamos Carla!!! 💪💪💪&#34;,&#34;#StayHome  #PlayAtHome \n#PokemonGOCommunityDay https://t.co/1k5Lx9IMaO&#34;,&#34;おはようございます😃☀\n4/25 #歩道橋の日\nそーいえばここ何年も、\n歩道橋を利用してないです。\n駅前直結スタイルならありますが。。\n\nさて。今日はケーシィ。\n#早速イロチ\n#あまりイロチ感なし\n#playathome\n#おこう3時間ww https://t.co/0XAO7hojF7 https://t.co/1Y9fmlRPxT&#34;,&#34;@MutuaMadridOpen Thiem&#34;,&#34;We’re missing 8 members of our #GISH #PlayAtHome team, is anyone part of Rhoades2Victory? @GISH #rolecall #scavengerhunt&#34;,&#34;@DonnaVekic @BelindaBencic @MutuaMadridOpen solid and consistent!&#34;,&#34;Thanks for your time @feliciano_lopez and congratulations on a great draw! Good luck with the #PlayAtHome #MMOpen @MutuaMadridOpen Hasta la vista 👍 https://t.co/Cmg5kTvelb&#34;,&#34;@MutuaMadridOpen @DavidFerrer87 No he visto a Deliciano en el cuadro va a ser director virtual del torneo?&#34;,&#34;@MutuaMadridOpen @DavidFerrer87 Nadal por supuesto..&#34;,&#34;@MutuaMadridOpen @atptour A gde vam je djokovic Majmuni&#34;,&#34;Looking for some cheap and easy entertainment to stimulate your brain? DIY (bilingual) puzzle races using a cracker box! Play against a family member or time yourself.  Challenge yourself further by mixing together ALL the pieces and try to solve both sides! #PlayAtHome #diy https://t.co/bEV0piRjXu&#34;,&#34;If you’re looking for something to keep you busy this weekend - we’ve launched another #PlayAtHome game!! 👏🏼💎 #PlayApartTogether https://t.co/igYETcSuu7&#34;,&#34;Tomorrow tomorrow I love ya tomorrow you’re only a dayyyy aaaaawaaaayyyy! 😍 #GISH #PlayAtHome&#34;,&#34;My favorite players taking part in the @MutuaMadridOpen Virtual Pro tournament. I hope @DonnaVekic wins! 🏆🐼🎾 https://t.co/4D1f21JBBO&#34;,&#34;The best game ever! #stayathome #playathome https://t.co/t8WctpQscM&#34;,&#34;#PlayAtHome https://t.co/ebqTaTSyeY&#34;],null,null,null,null,{&#34;interactive&#34;:false,&#34;permanent&#34;:false,&#34;direction&#34;:&#34;auto&#34;,&#34;opacity&#34;:1,&#34;offset&#34;:[0,0],&#34;textsize&#34;:&#34;10px&#34;,&#34;textOnly&#34;:false,&#34;className&#34;:&#34;&#34;,&#34;sticky&#34;:true},null]}],&#34;limits&#34;:{&#34;lat&#34;:[-38.19988735475,57.1605562],&#34;lng&#34;:[-122.857891,153.369361472]}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;

Even with the small proportion of tweets we can get an idea of where the audience for the tournament is. Leaflet provides nice interactivity, you can the map; if you click on the location pins you get the tweet.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;global-audience&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Global audience&lt;/h3&gt;
&lt;p&gt;Tennis is known to be a very interantional sport with fans all around the world. Separately from mapping the tweet locations we can examine which languages are most represented in the tweet set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(tw[,.N,lang][N&amp;gt;50], aes(x=lang,y=N)) + geom_bar(stat=&amp;quot;Identity&amp;quot;) + theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-01-analysing-tweets-from-the-virtual-madrid-open_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As expected English is the most represented language followed by Spanish. Not a big surprise since the tournament took place in Spain. Japanese comes in a surprising 3rd place due to the presence of Kei Nishikori.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sentiment-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sentiment analysis&lt;/h3&gt;
&lt;p&gt;So, how do people feel about this first attempt at an online tournament? We can use sentiment anlysis to go through all the tweets and classify them into positive or negative sentiment. There are several ways to do this, here I will opt for using the &lt;code&gt;sentimentr&lt;/code&gt; package which comes with some neat functions that evaluate sentiment directly without having to tokenise or pre-process the data.&lt;/p&gt;
&lt;p&gt;Here’s an example of how the package works. We take an example tweet…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;exampleText&amp;lt;-tw[lang==&amp;quot;en&amp;quot;,text][129]
exampleText&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;I thought the next gen would dominate the virtual #MMOPEN and one of them would be the champs. \n\nIt turned out that one of the big 4 stole the victory.\n\nShame on you, next gen &amp;lt;U+0001F609&amp;gt;&amp;lt;U+0001F61D&amp;gt;&amp;lt;U+0001F604&amp;gt;&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;…and then apply the &lt;code&gt;sentiment_by&lt;/code&gt; function to the tweet.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sentiment_by(exampleText)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    element_id word_count        sd ave_sentiment
## 1:          1         34 0.1980625    -0.1427715&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;sentiment_by&lt;/code&gt; takes the terms in the tweet and associates them to positive or negative sentiments to produce an average sentiment for that tweet. It also outputs thw word count and a standard deviation measure. In this case we can see that the sentiment is negative but given that the stadard deviation is larger than the estimate we cannot be absolutely certain.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;language-barrier&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Language barrier&lt;/h3&gt;
&lt;p&gt;Since the sentiment analysis pacakge is geared to work with English only my original idea was to take all the tweets in the most prevalent non-English langauges and translate them to English.&lt;/p&gt;
&lt;p&gt;To that end I was planning to use &lt;code&gt;TextBlob&lt;/code&gt;; a python pacakge for text analysis that comes with translation capabilities without requiring API keys.&lt;/p&gt;
&lt;p&gt;For those paying attention you would have noticed that I casually mention python. That’s right. Using the &lt;code&gt;reticulate&lt;/code&gt; package you can import python modules into R! I thought that’s pretty cool and wanted to showcase it in this analysis.&lt;/p&gt;
&lt;p&gt;Unfortunately, the translate funtion in &lt;code&gt;TextBlob&lt;/code&gt; actually has a limit to how much it can translate and that limit was nowhere close enough to translate all the tweet I have.&lt;/p&gt;
&lt;p&gt;In any case, this is how you would go about it:&lt;/p&gt;
&lt;p&gt;Import the python module and use it to make a text blob:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;require(reticulate)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;reticulate&amp;#39; was built under R version 3.5.3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tb&amp;lt;-import(&amp;quot;textblob&amp;quot;) #Import TextBlob
spanishTweet&amp;lt;-tb$TextBlob(tw[lang==&amp;quot;es&amp;quot;,][1,text]) #create a blob
spanishTweet&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Hoy debería de dar comienzo el @MutuaMadridOpen. Volveremos a disfrutar como siempre, como nunca. https://t.co/GOT7Yp4Eg8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Do the actual translation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;trans.spanishTweet&amp;lt;-spanishTweet$translate(from_lang = &amp;quot;es&amp;quot;, to=&amp;quot;en&amp;quot;)
trans.spanishTweet&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Today should start @MutuaMadridOpen. We will enjoy again as always, like never before. https://t.co/GOT7Yp4Eg8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The cool thing here is that we are using python within R. This specific case didn’t turn out like I wanted it to but think of the possibilities! Anyway, moving on…&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-actual-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The actual analysis&lt;/h3&gt;
&lt;p&gt;We are not able to get translated tweet so for now we’ll restrict our view to English tweets only.&lt;/p&gt;
&lt;p&gt;Also, I’m interested in the fans’ opinions so I will remove what I call ‘official’ accounts. These include the accounts for the tournament, offcial bodies and broadcasters.&lt;/p&gt;
&lt;p&gt;Finally, in my first pass at this I found I was getting some non-tennis related terms back. Turns out the #PlayAtHome term brings in tweets from other events such as concerts, other gaming events, etc. Since this is a quick analysis I decided to get rid of tweets with that hashtag.&lt;/p&gt;
&lt;p&gt;We can now calculate sentiment for all the remaining tweets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;twen &amp;lt;- tw[lang==&amp;quot;en&amp;quot;]
offical&amp;lt;-c(&amp;quot;MutuaMadridOpen&amp;quot;,&amp;quot;the_LTA&amp;quot;,&amp;quot;TennisChannel&amp;quot;,&amp;quot;WTA&amp;quot;,&amp;quot;atptour&amp;quot;,&amp;quot;Tennis&amp;quot;,&amp;quot;Eurosport_UK&amp;quot;)
twen&amp;lt;-twen[!screen_name %in% offical]
twen&amp;lt;-twen[!grep(&amp;quot;tHome|thome&amp;quot;,text)]
sent &amp;lt;- sentiment_by(get_sentences(twen[,(text)]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How is the sentiment distributed?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(sent,aes(ave_sentiment)) + geom_histogram(bins=50) + theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-01-analysing-tweets-from-the-virtual-madrid-open_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There is a big peak at 0 which represents neutral tweets. The distributions to either side of 0 show that sentiment is more positive than negative. So it seems that in general people liked the idea of the virtual Madrid Open.&lt;/p&gt;
&lt;p&gt;Let’s remove the neutral-sentiment tweets and plot the histogram again this time looking at the evolution per day.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;twen&amp;lt;-bind_cols(twen,sent)
twen[,sent_dir:=ifelse(ave_sentiment&amp;lt;0,&amp;quot;Negative&amp;quot;,ifelse(ave_sentiment&amp;gt;0,&amp;quot;Positive&amp;quot;,&amp;quot;Neutral&amp;quot;))]
ggplot(twen[abs(ave_sentiment)&amp;gt;0 &amp;amp; date(created_at)&amp;lt;&amp;quot;2020-05-01&amp;quot;],aes(ave_sentiment, fill=sent_dir)) + geom_histogram(bins = 50) + facet_wrap(.~date(created_at)) + theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-01-analysing-tweets-from-the-virtual-madrid-open_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The tournament started on the 27th. From these charts we can see how interest starts building up in the days prior and then peaks on the day the tournament starts. The number of tweets then decreases each day before having a bump on the final day.&lt;/p&gt;
&lt;p&gt;In terms of sentiment we can see that positive outweights negative every day but from the histograms it is not easy to see if the proportion changes.&lt;/p&gt;
&lt;p&gt;We can tabulate the proportion of postive and negative tweets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;percs&amp;lt;-twen[abs(ave_sentiment)&amp;gt;0 &amp;amp; date(created_at)&amp;lt;&amp;quot;2020-05-01&amp;quot;,.N,.(date(created_at),sent_dir)][sent_dir!=&amp;quot;Neutral&amp;quot;][,.(sent_dir,p=round(100*N/sum(N))),date]
kable(dcast(percs,sent_dir~date,value.var=&amp;quot;p&amp;quot;),format = &amp;#39;html&amp;#39;) %&amp;gt;% kable_styling(bootstrap_options = &amp;#39;striped&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
sent_dir
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
2020-04-23
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
2020-04-24
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
2020-04-25
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
2020-04-26
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
2020-04-27
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
2020-04-28
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
2020-04-29
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
2020-04-30
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Negative
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
33
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
24
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Positive
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
77
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
72
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
85
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
77
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
67
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
77
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
76
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The proportion of positive sentiment is in the high 70s and 80s for most days. The glaring exception happened on the 27th when the tournament started. Negative sentiment goes up to 32%. Let’s try to figure out why by looking at some wordclouds.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;wordclouds-from-sentiment-terms&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Wordclouds from sentiment terms&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;extract_sentiment_terms&lt;/code&gt; function tells us which terms in the tweets contributed to the sentiment score.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;terms&amp;lt;-extract_sentiment_terms((twen[,text]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can visualise these terms using the &lt;code&gt;wordcloud&lt;/code&gt; package. I will make one cloud for positive terms and one for negative ones.&lt;/p&gt;
&lt;p&gt;Before constructing the clouds I’m removing stop words, common terms like ‘at’,‘the’,‘in’, that do not contribute to sentiment. Apart from the terms in the stop_words array provided by the &lt;code&gt;tidytext&lt;/code&gt; pacakge I’m also removing some custom terms that will be very common in our tweet set but which won’t tell us much about sentiment.&lt;/p&gt;
&lt;p&gt;The postive-term cloud:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_sw&amp;lt;-c(stop_words$word,&amp;quot;virtual&amp;quot;,&amp;quot;pro&amp;quot;,&amp;quot;play&amp;quot;,&amp;quot;game&amp;quot;,&amp;quot;tennis&amp;quot;,&amp;quot;players&amp;quot;,&amp;quot;madrid&amp;quot;,&amp;quot;match&amp;quot;,&amp;quot;video&amp;quot;,&amp;quot;games&amp;quot;,&amp;quot;player&amp;quot;,&amp;quot;players&amp;quot;,&amp;quot;tournament&amp;quot;)

u&amp;lt;-data.table(words=unlist(terms[,positive]))[,.N,words][order(-N)]
u&amp;lt;-u[!words %in% my_sw]
par(mfrow=c(1,2))
wc_pos&amp;lt;-wordcloud(words = u$words, freq = u$N, min.freq = 1,max.words=200, random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, &amp;quot;Dark2&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-01-analysing-tweets-from-the-virtual-madrid-open_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Positive terms are what you would expect with things like “win”, “fun”, “luck” and “congrats” having the biggest size.&lt;/p&gt;
&lt;p&gt;The negative-term cloud:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;u&amp;lt;-data.table(words=unlist(terms[,negative]))[,.N,words][order(-N)]
u&amp;lt;-u[!words %in% my_sw]
wc_neg&amp;lt;-wordcloud(words = u$words, freq = u$N, min.freq = 1,max.words=200, random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, &amp;quot;Dark2&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-01-analysing-tweets-from-the-virtual-madrid-open_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Regarding negative terms apart from traditionally negative words it is interesting to see things like “issues”, “twitch”, “controller”. “Twitch” could be fans aluding to the fact that it would have been better to hold the tournament in that platform.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;wordclouds-from-tweets&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Wordclouds from tweets&lt;/h3&gt;
&lt;p&gt;Finally, we can also build wordlcouds directly from the tweets. We can make a positive-term wordcloud from the tweets with positive average sentiment and analogously for the negative terms.&lt;/p&gt;
&lt;p&gt;First, let’s do a quick cleaning of the text data so it doesn’t appear in the clouds.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;twen[,text2 := gsub(&amp;quot;https\\S*&amp;quot;, &amp;quot;&amp;quot;, text)]
twen[,text2 := gsub(&amp;quot;@\\S*&amp;quot;, &amp;quot;&amp;quot;, text2) ]
twen[,text2 := gsub(&amp;quot;#\\S*&amp;quot;, &amp;quot;&amp;quot;, text2) ]
twen[,text2 := gsub(&amp;quot;amp&amp;quot;, &amp;quot;&amp;quot;, text2) ]
twen[,text2 := gsub(&amp;quot;[\r\n]&amp;quot;, &amp;quot;&amp;quot;, text2)]
twen[,text2 := gsub(&amp;quot;[[:punct:]]&amp;quot;, &amp;quot;&amp;quot;, text2)]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now make the wordclouds.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;u&amp;lt;-unnest_tokens(twen[!grep(&amp;quot;atHome&amp;quot;,text)][ave_sentiment&amp;gt;0,.(text2)],words,text2)[,.N,words][order(-N)]
u&amp;lt;-u[!words %in% my_sw]
wordcloud(words = u$words, freq = u$N, min.freq = 5,max.words=200, random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, &amp;quot;Dark2&amp;quot;),scale = c(1.5,0.5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-01-analysing-tweets-from-the-virtual-madrid-open_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This time there’s a lot more terms in the wordcloud because the tweets are richer than the extracted term data. Many of the extra terms are realted to player names. Otherwise we see similar type of words as in the extracted term cloud.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;u&amp;lt;-unnest_tokens(twen[!grep(&amp;quot;atHome&amp;quot;,text)][ave_sentiment&amp;lt;0,.(text2)],words,text2)[,.N,words][order(-N)]
u&amp;lt;-u[!words %in% my_sw]
wordcloud(words = u$words, freq = u$N, min.freq = 3,max.words=200, random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, &amp;quot;Dark2&amp;quot;), scale = c(1.5,0.5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-01-analysing-tweets-from-the-virtual-madrid-open_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The negative-tweet word cloud also now includes a lot of player names but we can see more hints of what poeple didn’t like so much, i.e., terms like “commentators”,&#34; internet“,”wait&#34; and “facebook”.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;We went on a whirlwind tour of several packages that can be used to analyse tweets or other types of text data. This is really only scratching the surface of what can be done so it will be interesting to keep exploring these packages and other ones such as &lt;code&gt;spacy&lt;/code&gt; and &lt;code&gt;quanteda&lt;/code&gt; which are used to do more complex things like parts-of-speech tagging, more comprehensive feature extraction and they also support more language models.&lt;/p&gt;
&lt;p&gt;In terms of the tournament, there were some teething issues like the choice of streaming platform, players with bad internet connections and too much commentary rather than having players mic’ed up. However, the overall sentiment was positive and people seemed to welcome this type of innovation from the organisers. We’ll see how future online tournaments fare.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>